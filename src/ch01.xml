<?xml-model title="DocBook customization for the XProc book"
            href="../schemas/xproc.rnc" 
            type="application/relax-ng-compact-syntax" ?>
<chapter xmlns="http://docbook.org/ns/docbook"
         xmlns:cx="http://xmlcalabash.com/ns/extensions"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:p="http://www.w3.org/ns/xproc"
         version="5.0-xproc" xml:id="introduction">
<info>
<title>Introduction</title>
</info>

<para>In this chapter, we’ll fill in some background about pipelines
and get you up to speed on the concepts before we dive into the actual
features of XProc. We’re going to assume that you’re familiar with
XML: you’re comfortable the vocabulary of tags and attributes, parsing
and validation, and that you’ve used an XML application or two: XSLT,
for example.</para>

<section xml:id="whatis">
<title>What’s a pipeline?</title>

<para>At a high level of abstraction, a pipeline is what you get
whenever the output of one process feeds into the input of another.
If you work with XML, you’ve probably already used pipelines
even if you didn’t think about them in those terms. If you validate
a document and then transform it, or if you apply XInclude and then
validate, or if you use XSLT to run two differen transformations,
those are all simple “pipeline” operations.</para>

<para>In another context, pipelines are a common feature of Unix
command lines, for example:</para>

<screen>cat ch01.xml | grep "&lt;para" | wc -l</screen>

<para>What that says is:</para>

<orderedlist>
<listitem>
<para>Run the <command>cat</command> command over
<filename>ch01.xml</filename>. That will display the contents of the file.
</para>
</listitem>
<listitem>
<para>The “|” symbol means that instead of displaying those lines in
the shell window, that output will become the input to the
<command>grep</command> command. What <command>grep</command> will do
is display all the lines that contain “<literal>&lt;para</literal>”
and discard all the rest.</para>
</listitem>
<listitem>
<para>Finally, with another “|”, the output of <command>grep</command> will
become the input to <command>wc</command>. The <command>wc</command> command
counts the words in a file, but we gave it the <option>-l</option> option, so
it will count the lines instead.</para>
</listitem>
</orderedlist>

<para>What this pipeline does is print the number of paragraphs in the
document:</para>

<screen>$ cat ch01.xml | grep "&lt;para" | wc -l
51</screen>

<para>By using a pipeline we’ve taken three useful utilities and
composed them together to create a pipeline that will count the
approximate number of paragraphs we’ve used in all the XML documents
in the current directory. I say approximately because those are all line-based
commands and XML isn’t really line based. Our XML editor might have saved
our XML files with great big long lines so that there’s more than one
“<literal>&lt;para>…&lt;/para></literal>” per line which would throw off
the counts.</para>

<para>Part of the power of Unix comes from the fact that it provides a
large and useful vocabulary of focused commands and a mechnanism for easily
composing them. By the same token, the XML technology stack provides a
large and useful vocabulary of “commands”: parsing, validation,
transformation, XInclude, XML Base, escaping and unescaping markup,
document comparison, etc. What’s historically been missing is a standard,
easy to use composition mechnaism.</para>

<para>Which isn’t meant to suggest that XProc invented the notion of
XML pipelines. Far from it, in fact. For as long as there have been
APIs for processing XML, there have been mechanisms for constructing
pipelines. One of the explicit goals of the XProc development exercise
was to invent as little as possible: the committee attempted to survey
the landscape of existing pipeline technologies and standardize the
common core. The key features that XProc introduces are
standardization and ease of use.</para>

<para>Through standardization we hope to foster the development of
interoperable pipelines. The pipelines that you run in your web
framework should also run on my command line and the pipelines that
run on my command line should also run in your XML editor.</para>

<para>The ease of use goal is met, we hope, by providing an XML
vocabulary for describing pipelines. That’s what XProc really is. We
hope that an analogy with XSLT is apt. Before XSLT, it was obviously
possible for programmers to transform XML documents. What XSLT
provided was an XML-based model that opened transformation up to a
much wider audience. Many people who are able to write XSLT transformations
would not feel comfortable writing a transformation application in a
standard programming language.</para>

<para>Before XProc, it was obviously possible for programmers to build
XML pipelines. What XProc provides is an XML-based model that we hope
will make it possible for a much wider audience to take advantage of
the benefits of focused tools, loosely connected through pipelines.
The fact that many projects developed their own vocabularies for exactly
this purpose makes us optimistic that having a standard mechanism will
be widely successful.</para>

<para>So what does an XML pipeline look like? Here’s an XProc pipeline
that counts the number of paragraphs in a document:</para>

<programlisting
><xi:include href="examples/countparas.xpl" parse="text"
/></programlisting>

<para>What this pipeline does is produce a single XML document that
contains the number of DocBook <tag>para</tag> elements in the
document:</para>

<screen>$ calabash -isource=ch01.xml examples/countparas.xpl
&lt;c:result xmlns:c="http://www.w3.org/ns/xproc-step">51&lt;/c:result></screen>

<para>It’s not completely isomorphic to the Unix command line example because
the abstractions are just a little bit different. Where the command line tools
work with lines, XProc uses documents, where the command line tools use
regular expressions, XProc uses XPath.</para>

<para>We’ll cover all the
details in subsequent chapters, but here’s a short summary of how this
pipeline works:</para>

<orderedlist>
<listitem>
<para>There’s nothing equivalent to the <command>cat</command> command because
the pipeline expects the processor to pass it the document(s) to process.
</para>
</listitem>
<listitem>
<para>Where <command>grep</command> used a regular expression to find
lines that contain “<literal>&lt;para</literal>”,
the XProc pipeline uses an XPath expression to select precisely the
DocBook paragraph elements. (The <tag>p:identity</tag> step copies its
to its output, unchanged; by selecting all the paragraphs on input, we
get every paragraph in a separate document on output.)
</para>
</listitem>
<listitem>
<para>The <tag>p:count</tag> step just counts the documents that come to it,
producing as output a single <tag>c:result</tag> element containing the
number of documents it saw.
</para>
</listitem>
</orderedlist>

<para>In fairness, that’s not a very useful pipeline. It was chosen for
its similarity to the preceding Unix example. Here’s a more realistic
XProc pipeline:</para>

<programlisting
><xi:include href="examples/simple.xpl" parse="text"
/></programlisting>

<para>That pipeline performs XInclude, RELAX NG validation, then
transformation. These pipelines are all quite simple. As we’ll see,
pipelines can be very sophisticated: they can interact with web services,
make choices, iterate over sequences, recover from errors, and be
extended in a variety of ways.</para>
</section>

<section xml:id="why">
<title>Why pipelines?</title>

<para>Although there are exceptions, many XML technologies were designed
with a very specific focus: XML base is about base URIs, XInclude is about
transclusion, XQuery and XSLT are about querying and transformation, XML
Schema and RELAX NG are about validation, etc.</para>

<para>There are many common use cases where the order and interaction
between these processes is obvious. Your favorite stylesheet
processor, for example, may give you options for performing validation
or XInclude processing, or both. That processor supports the most
common scenario of those technologies: XInclude, followed by
validation, followed by transformation. In fact, those options allow
you to control a very limited pipeline within the product.</para>

<para>But equally, there are many use cases where the order and
interaction between these process is not simply less obvious, it
doesn’t exist:</para>

<itemizedlist>
<listitem>
<para>You might want to validate <emphasis>before</emphasis> performing
XInclude processing (in order to determine if the <tag>xi:include</tag>
elements themselves occurred in legal places). You might then want to
perform validation <emphasis>again</emphasis>, probably with a
<emphasis>different schema</emphasis> after XInclude to assess the validity
of the composed document.</para>
</listitem>
<listitem>
<para>Along the same lines, you might want to perform validation both
before and after a transformation.</para>
</listitem>
<listitem>
<para>If a document can’t be processed by some part of a pipeline, you
might want to recover in application-specific ways.</para>
</listitem>
<listitem>
<para>You might want to interact with a web service as part of a larger
process, perhaps choosing to perform different kinds of processing depending
on the result of that interaction.</para>
</listitem>
</itemizedlist>

<para>In these and countless other scenarious, the order and sequence of
steps has no single, predefined, correct order.</para>

<para>Decomposing a complex “business process” (to use the vernacular)
into a sequence of simpler steps, operations on XML documents in our
case, is a natural and powerful abstraction. What’s needed to achieve
this vision is some “glue language” that allows us to express the nature
and order of operations that comprise our application: we need a pipeline
language.</para>

<para>Dozens of vendor and application-specicific languages have been
invented for this task.</para>
</section>

<section xml:id="procmodel">
<title>Processing Model</title>

<para>There are many different ways to model pipelines. The examples
above are completely linear pipelines where each step requires a very
small amount of context. These pipelines are simple and fast, but can
only support the kinds of processes that require no branching and very
little context.</para>

<para>This model can be expanded and generalized to what we might call
the “flowing water” pipeline model. These are conceptually just like
the oil, water, and natural gas pipelines we are familiar with in the
real world. In an oil pipeline, there are processing stations of
various sorts (reservoirs, filters, valves, distillation plants, etc.)
connected together by physical pipelines. Crude oil flows in at one
end and moves from station to station through pipes. Each stations
performs some process and directs the resulting output through one or
more pipes to the next process. In an XML pipeline, the processing
stations are XML processes and the pipelines are the pathways down
which XML documents may “flow”.</para>

<para>Another model is based on events and state transitions. In this
model there are no fixed pathways between processes. Rather, each document
has an associated state and each step in the process applies some action
and optionally moves the document to another state. Event driven pipelines
may process a document many times, moving it through a complex network of
states until some step concludes that the work is done. They are flexible
and powerful, but can be tricky to understand.</para>

<para>XProc pipelines follow the “flowing water” model. This model was
selected because it’s sufficiently powerful to address many real use
cases and also conceptually quite easy to explain and
understand.</para>

</section>

<section xml:id="streaming">
<title>Streaming</title>

<para>The discussion of a processing model raises the question of
streaming. Streaming is difficult to define succinctly. For our
purposes it’s sufficient to say that a streaming process differs from
a non-streaming one if it can process an arbitrarily large document,
or arbitrarily many documens, without running out of memory.</para>

<para>Some steps are more naturally streamable than others. A step
that deletes all elements that have a <att>revisionflag</att>
attribute with the value “<literal>deleted</literal>”, is conceptually easy
to stream. A step that adds an attribute to the document element
if the document contains an odd number of elements with no attributes
appears impossible to stream.</para>

<para>XProc tries very hard to be neutral about streaming. There’s no
requirement that an implementation be able to stream, but the language
attempts to avoid imposing semantics that would prevent it from
streaming.</para>

</section>

<section xml:id="anatomy">
<title>Anatomy of a pipeline</title>

<para>Generally speaking, an XProc pipeline document has a document
element of <tag>p:pipeline</tag> (or possibly
<tag>p:declare-step</tag>) and contains one or more steps. The steps
are connected, either implicitly or explicitly, and documents flow
between steps along those connections. The type of each step
determines what kind of processing it
performs.</para>

<para>In addition to the connections between them, steps can have options
and parameters, some steps can be nested, variables may be declared,
etc.</para>

<para>We’ll consider the anatomy of pipelines in more detail in the
following chapters.</para>
</section>

<section xml:id="running">
<title>Running XProc Pipelines</title>

<para>In order to run an XProc pipeline, you need an XProc processor.
At the time of this writing, there are several options listed at
<link xlink:href="http://xproc.org/implementations/"/>. The author’s
implementation is
<citetitle xlink:href="http://xmlcalabash.com/">XML Calabash</citetitle>.</para>

<para>All pipelines that conform to
<link xlink:href="http://www.w3.org/TR/xproc/">XProc: An XML Pipeline Language</link>
should produce the same results if run by any conformant processor.
Not surprisingly, we’re going to use
<link xlink:href="http://xmlcalabash.com/">XML Calabash</link> for most of our
examples in this book.</para>

</section>

<section xml:id="interop">
<title>Interoperability</title>

<para>All pipelines that conform to
<link xlink:href="http://www.w3.org/TR/xproc/">XProc: An XML Pipeline Language</link>
should produce the same results if run by any conformant processor—if the processor
supports all the steps used.</para>

<para>Steps come in three flavors: required steps, optional steps, and extension
steps. The required and optional steps are described in the
<link xlink:href="http://www.w3.org/TR/xproc/">XProc specification</link>.
As you could probably guess, all processors are required to support the
required steps but may or may not choose to support (all of) the optional
steps. Any step not described in the specification is an extension step.
</para>

<para>Extension steps come in a few flavors as well. Every pipeline has the
potential to be used as a step in another pipeline. Extension steps implemented
as XProc pipelines are, naturally, every bit as interoperable as the steps
they contain.</para>

<para>Implementations may also support the creation of extension steps
directly using whatever APIs their underlying programming language supports.
In <xref linkend="xcalabash"/>, we’ll examine how you can write your own
XML Calabash extensions in Java. Such steps are only going to work in the
implementation for which they were written.</para>

<para>There’s one last wrinkle in this story. The
<link xlink:href="http://exproc.org/"/> website is attempting to collect
a set of community-supported extension steps. With luck, the vocabulary
of extensions defined at EXProc.org will also be portable across different
implementations.</para>
</section>

</chapter>
